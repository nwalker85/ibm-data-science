{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599356444789",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Crash Severity Prediction Model</h1>\n",
    "\n",
    "Let's build a model to predict the severity of a crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a list containing all of the columns we'll use for our model\n",
    "\n",
    "filtered_columns =  [\n",
    " 'Schl_Bus_Fl',\n",
    " 'Rr_Relat_Fl',\n",
    " 'Active_School_Zone_Fl',\n",
    " 'Crash_Date',\n",
    " 'Crash_Time',\n",
    " 'Toll_Road_Fl',\n",
    " 'Crash_Speed_Limit',\n",
    " 'Road_Constr_Zone_Fl',\n",
    " 'Road_Constr_Zone_Wrkr_Fl',\n",
    " 'At_Intrsct_Fl',\n",
    " 'Wthr_Cond_ID',\n",
    " 'Light_Cond_ID',\n",
    " 'Road_Type_ID',\n",
    " 'Road_Algn_ID',\n",
    " 'Surf_Cond_ID',\n",
    " 'Intrsct_Relat_ID',\n",
    " 'FHE_Collsn_ID',\n",
    " 'Obj_Struck_ID',\n",
    " 'Othr_Factr_ID',\n",
    " 'Road_Part_Adj_ID',\n",
    " 'Road_Cls_ID',\n",
    " 'Road_Relat_ID',\n",
    " 'Phys_Featr_1_ID',\n",
    " 'Phys_Featr_2_ID',\n",
    " 'Pop_Group_ID',\n",
    " 'Day_of_Week',\n",
    " 'Base_Type_ID',\n",
    " 'Surf_Type_ID',\n",
    " 'Adt_Adj_Curnt_Amt',\n",
    " 'Trk_Aadt_Pct',\n",
    " 'Curve_Type_ID',\n",
    " 'Curve_Lngth',\n",
    " 'Cd_Degr',\n",
    " 'Delta_Left_Right_ID',\n",
    " 'Dd_Degr',\n",
    " 'WDCode_ID',\n",
    " 'Crash_Sev_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need a list of just the predictor columns\n",
    "\n",
    "predictor_columns =  [\n",
    " 'Schl_Bus_Fl',\n",
    " 'Rr_Relat_Fl',\n",
    " 'Active_School_Zone_Fl',\n",
    " 'Crash_Date',\n",
    " 'Crash_Time',\n",
    " 'Toll_Road_Fl',\n",
    " 'Crash_Speed_Limit',\n",
    " 'Road_Constr_Zone_Fl',\n",
    " 'Road_Constr_Zone_Wrkr_Fl',\n",
    " 'At_Intrsct_Fl',\n",
    " 'Wthr_Cond_ID',\n",
    " 'Light_Cond_ID',\n",
    " 'Road_Type_ID',\n",
    " 'Road_Algn_ID',\n",
    " 'Surf_Cond_ID',\n",
    " 'Intrsct_Relat_ID',\n",
    " 'FHE_Collsn_ID',\n",
    " 'Obj_Struck_ID',\n",
    " 'Othr_Factr_ID',\n",
    " 'Road_Part_Adj_ID',\n",
    " 'Road_Cls_ID',\n",
    " 'Road_Relat_ID',\n",
    " 'Phys_Featr_1_ID',\n",
    " 'Phys_Featr_2_ID',\n",
    " 'Pop_Group_ID',\n",
    " 'Day_of_Week',\n",
    " 'Base_Type_ID',\n",
    " 'Surf_Type_ID',\n",
    " 'Adt_Adj_Curnt_Amt',\n",
    " 'Trk_Aadt_Pct',\n",
    " 'Curve_Type_ID',\n",
    " 'Curve_Lngth',\n",
    " 'Cd_Degr',\n",
    " 'Delta_Left_Right_ID',\n",
    " 'Dd_Degr',\n",
    " 'WDCode_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                  level_0  level_1  Crash_ID  \\\n0       extract_public_2018_20200825003448226_69851_20...        0  15657177   \n1       extract_public_2018_20200825003448226_69851_20...        1  16406486   \n2       extract_public_2018_20200825003448226_69851_20...        2  16473665   \n3       extract_public_2018_20200825003448226_69851_20...        3  16871051   \n4       extract_public_2018_20200825003448226_69851_20...        4  16995273   \n...                                                   ...      ...       ...   \n648332  extract_public_2018_20200825003448226_69851_20...    54572  17777131   \n648333  extract_public_2018_20200825003448226_69851_20...    54573  17779640   \n648334  extract_public_2018_20200825003448226_69851_20...    54574  17783015   \n648335  extract_public_2018_20200825003448226_69851_20...    54575  17801355   \n648336  extract_public_2018_20200825003448226_69851_20...    54576  17813604   \n\n       Crash_Fatal_Fl Cmv_Involv_Fl Schl_Bus_Fl Rr_Relat_Fl  \\\n0                   N             N           N           N   \n1                   N             N           N           N   \n2                   N             N           N           N   \n3                   N             Y           N           N   \n4                   N             N           N           N   \n...               ...           ...         ...         ...   \n648332              N             N           N           N   \n648333              N             N           N           N   \n648334              N             N           N           N   \n648335              N             N           N           N   \n648336              N             N           N           N   \n\n       Medical_Advisory_Fl Amend_Supp_Fl Active_School_Zone_Fl  ...  \\\n0                        N             Y                     N  ...   \n1                        N             Y                     N  ...   \n2                        N             Y                     N  ...   \n3                        N             Y                     N  ...   \n4                        N             Y                     N  ...   \n...                    ...           ...                   ...  ...   \n648332                   N             N                     N  ...   \n648333                   N             N                     N  ...   \n648334                   N             N                     N  ...   \n648335                   N             N                     N  ...   \n648336                   N             N                     N  ...   \n\n       Nonincap_Injry_Cnt Poss_Injry_Cnt Non_Injry_Cnt Unkn_Injry_Cnt  \\\n0                       0              0             0              1   \n1                       0              0             1              1   \n2                       1              0             1              0   \n3                       0              0             2              0   \n4                       0              1             6              0   \n...                   ...            ...           ...            ...   \n648332                  0              0             0              2   \n648333                  0              0             2              0   \n648334                  0              0             0              1   \n648335                  0              0             1              0   \n648336                  0              0             2              0   \n\n        Tot_Injry_Cnt  Death_Cnt MPO_ID Investigat_Service_ID  \\\n0                   0          0    NaN                  35.0   \n1                   0          0    NaN                  23.0   \n2                   1          0    NaN                  35.0   \n3                   0          0  282.0                   NaN   \n4                   1          0   15.0                  53.0   \n...               ...        ...    ...                   ...   \n648332              0          0    NaN                  29.0   \n648333              0          0   15.0                   NaN   \n648334              0          0    NaN                 411.0   \n648335              0          0   15.0                   NaN   \n648336              0          0   96.0                   NaN   \n\n        Investigat_DA_ID  Investigator_Narrative  \n0                    NaN                     NaN  \n1                    NaN                     NaN  \n2                    NaN                     NaN  \n3                    NaN                     NaN  \n4                   61.0                     NaN  \n...                  ...                     ...  \n648332              14.0                     NaN  \n648333               NaN                     NaN  \n648334               NaN                     NaN  \n648335               NaN                     NaN  \n648336               NaN                     NaN  \n\n[648337 rows x 173 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>level_0</th>\n      <th>level_1</th>\n      <th>Crash_ID</th>\n      <th>Crash_Fatal_Fl</th>\n      <th>Cmv_Involv_Fl</th>\n      <th>Schl_Bus_Fl</th>\n      <th>Rr_Relat_Fl</th>\n      <th>Medical_Advisory_Fl</th>\n      <th>Amend_Supp_Fl</th>\n      <th>Active_School_Zone_Fl</th>\n      <th>...</th>\n      <th>Nonincap_Injry_Cnt</th>\n      <th>Poss_Injry_Cnt</th>\n      <th>Non_Injry_Cnt</th>\n      <th>Unkn_Injry_Cnt</th>\n      <th>Tot_Injry_Cnt</th>\n      <th>Death_Cnt</th>\n      <th>MPO_ID</th>\n      <th>Investigat_Service_ID</th>\n      <th>Investigat_DA_ID</th>\n      <th>Investigator_Narrative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>0</td>\n      <td>15657177</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>1</td>\n      <td>16406486</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>23.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>2</td>\n      <td>16473665</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>3</td>\n      <td>16871051</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>282.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>4</td>\n      <td>16995273</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>15.0</td>\n      <td>53.0</td>\n      <td>61.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>648332</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>54572</td>\n      <td>17777131</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>29.0</td>\n      <td>14.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>648333</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>54573</td>\n      <td>17779640</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>648334</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>54574</td>\n      <td>17783015</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>411.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>648335</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>54575</td>\n      <td>17801355</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>648336</th>\n      <td>extract_public_2018_20200825003448226_69851_20...</td>\n      <td>54576</td>\n      <td>17813604</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>96.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>648337 rows Ã— 173 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Import the data to a pandas data frame\n",
    "\n",
    "root = \"extract_public_2018_20200825003448226_69851_20190101-20191231Texas/\"\n",
    "files = glob(root + '*/*_crash_*.csv')\n",
    "get_df = lambda f: pd.read_csv(f)\n",
    "dfdict = {f: pd.read_csv(f) for f in files}\n",
    "df = pd.concat(dfdict)\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the imported data based on our selected features.\n",
    "\n",
    "df_filtered = df[filtered_columns]\n",
    "#df_filtered = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where there is no crash severity ID listed. This is our target column, so these rows are useless\n",
    "\n",
    "df_filtered = df_filtered[df_filtered.Crash_Sev_ID != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also drop all rows where the speed limit is -1, which is a effectively a \"NaN\" value.\n",
    "df_filtered = df_filtered[df_filtered['Crash_Speed_Limit']!=-1]\n",
    "\n",
    "# df_filtered.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "df_filtered['Crash_Time'] = pd.to_datetime(df_filtered['Crash_Time']).astype('int64')\n",
    "\n",
    "values = df_filtered['Crash_Time'].values\n",
    "values = values.reshape((len(values), 1))\n",
    "\n",
    "df_filtered['NORMTIME'] = scaler.fit_transform(values)\n",
    "\n",
    "df_filtered.drop('Crash_Time', axis=1, inplace=True)\n",
    "df_filtered.rename(columns={'NORMTIME' : \"Crash_Time\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['Crash_Date'] = pd.to_datetime(df_filtered['Crash_Date']).astype('int64')\n",
    "\n",
    "values = df_filtered['Crash_Date'].values\n",
    "values = values.reshape((len(values), 1))\n",
    "\n",
    "df_filtered['NORMDATE'] = scaler.fit_transform(values)\n",
    "\n",
    "df_filtered.drop('Crash_Date', axis=1, inplace=True)\n",
    "df_filtered.rename(columns={'NORMDATE' : \"Crash_Date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.Day_of_Week.replace(to_replace=r'^MON$', value=1, regex=True, inplace=True)\n",
    "df_filtered.Day_of_Week.replace(to_replace=r'^TUE$', value=2, regex=True, inplace=True)\n",
    "df_filtered.Day_of_Week.replace(to_replace=r'^WED$', value=3, regex=True, inplace=True)\n",
    "df_filtered.Day_of_Week.replace(to_replace=r'^THU$', value=4, regex=True, inplace=True)\n",
    "df_filtered.Day_of_Week.replace(to_replace=r'^FRI$', value=5, regex=True, inplace=True)\n",
    "df_filtered.Day_of_Week.replace(to_replace=r'^SAT$', value=6, regex=True, inplace=True)\n",
    "df_filtered.Day_of_Week.replace(to_replace=r'^SUN$', value=7, regex=True, inplace=True)\n",
    "\n",
    "values = df_filtered['Day_of_Week'].values\n",
    "values = values.reshape((len(values), 1))\n",
    "\n",
    "df_filtered['NORMDAY'] = scaler.fit_transform(values)\n",
    "\n",
    "df_filtered.drop('Day_of_Week', axis=1, inplace=True)\n",
    "df_filtered.rename(columns={'NORMDAY' : \"Day_of_Week\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to normalize our text values - y/n to 1/0, and the days of the week normalized to values between 1 and 7.\n",
    "\n",
    "df_filtered.replace(to_replace=r'^N$', value=0, regex=True, inplace=True)\n",
    "df_filtered.replace(to_replace=r'^Y$', value=1, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Balance the data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overfitting for a given target value, let's make sure the data is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the crash severity IDs\n",
    "\n",
    "sns.countplot(x='Crash_Sev_ID', data=df_filtered)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is HEAVILY skewed towards 5, no injury. If we try to train as is, his is going to result in a model that predicts 5 more often than not, just by virtue of it appear most often in the data. \n",
    "\n",
    "Let's avoid this problem by balancing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_1, count_class_2, count_class_3, count_class_4, count_class_5 = df_filtered.Crash_Sev_ID.value_counts()\n",
    "df_class_1 = df_filtered[df_filtered['Crash_Sev_ID'] == 1]\n",
    "df_class_2 = df_filtered[df_filtered['Crash_Sev_ID'] == 2]\n",
    "df_class_3 = df_filtered[df_filtered['Crash_Sev_ID'] == 3]\n",
    "df_class_4 = df_filtered[df_filtered['Crash_Sev_ID'] == 4]\n",
    "df_class_5 = df_filtered[df_filtered['Crash_Sev_ID'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_5_under = df_class_5.sample(count_class_5)\n",
    "df_class_3_under = df_class_3.sample(count_class_5)\n",
    "df_class_2_under = df_class_2.sample(count_class_5)\n",
    "df_class_1_under = df_class_1.sample(count_class_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_under = pd.concat([df_class_5_under, df_class_3_under, df_class_2_under, df_class_1_under, df_class_4], axis=0)\n",
    "df_test_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Random under-sampling:')\n",
    "print(df_test_under.Crash_Sev_ID.value_counts())\n",
    "df_test_under.Crash_Sev_ID.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_5_over = df_class_5.sample(count_class_1, replace=True)\n",
    "df_class_4_over = df_class_4.sample(count_class_1, replace=True)\n",
    "df_class_3_over = df_class_3.sample(count_class_1, replace=True)\n",
    "df_class_2_over = df_class_2.sample(count_class_1, replace=True)\n",
    "df_class_1_over = df_class_1.sample(count_class_1, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_over = pd.concat([df_class_4_over, df_class_3_over, df_class_2_over, df_class_1_over, df_class_5], axis=0)\n",
    "df_test_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Random over-sampling:')\n",
    "print(df_test_over.Crash_Sev_ID.value_counts())\n",
    "df_test_over.Crash_Sev_ID.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two datasets that are much more balanced. But because of the sampling methods, we may run into issues down the line. We'll test both frames and compare the resulting models to see which is more useful for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decision Tree</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_test_over[predictor_columns].values\n",
    "y = df_test_over[\"Crash_Sev_ID\"]\n",
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "crashTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 3)\n",
    "crashTree.fit(X_trainset,y_trainset)\n",
    "predTree = crashTree.predict(X_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_testset, predTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true=y_testset, y_pred=predTree)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_under[predictor_columns].values\n",
    "y = df_test_under[\"Crash_Sev_ID\"]\n",
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "crashTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 3)\n",
    "crashTree.fit(X_trainset,y_trainset)\n",
    "predTree = crashTree.predict(X_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_testset, predTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true=y_testset, y_pred=predTree)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that neither model is performing particularly well, but adjusting the max_depth may return better results. Let's find the best value for max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_over[predictor_columns].values\n",
    "y = df_test_over[\"Crash_Sev_ID\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "max_depths = np.linspace(1, 60, 60, endpoint=True)\n",
    "train_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth)\n",
    "   dt.fit(x_train, y_train)\n",
    "   train_pred = dt.predict(x_test)\n",
    "   train_pred_score = metrics.accuracy_score(y_test, train_pred)\n",
    "   train_results.append(train_pred_score)\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1 = plt.plot(max_depths, train_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_under[predictor_columns].values\n",
    "y = df_test_under[\"Crash_Sev_ID\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "max_depths = np.linspace(1, 60, 60, endpoint=True)\n",
    "train_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth)\n",
    "   dt.fit(x_train, y_train)\n",
    "   train_pred = dt.predict(x_test)\n",
    "   train_pred_score = metrics.accuracy_score(y_test, train_pred)\n",
    "   train_results.append(train_pred_score)\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1 = plt.plot(max_depths, train_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The under sampled data maxes out at 34% accuracy, which is not going to be usable for a model. But the oversampled data can get over 90% with a max_depth of around 35 before we start leveling off. We'll use the oversampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_test_over[predictor_columns].values\n",
    "y = df_test_over[\"Crash_Sev_ID\"]\n",
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "crashTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 35)\n",
    "crashTree.fit(X_trainset,y_trainset)\n",
    "predTree = crashTree.predict(X_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_testset, predTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_testset, predTree, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "CM = confusion_matrix(y_testset, predTree)\n",
    "CM = CM / CM.astype(np.float).sum(axis=1)\n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(CM, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks really solid.  Recall is the model metric we use to select our best model when there is a high cost associated with False Negative. We have a recall of 1 for the value of 4, fatal accidents. We cannot afford to miss this prediction, so this may be a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_over[predictor_columns].values\n",
    "y = df_test_over[\"Crash_Sev_ID\"]\n",
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_trainset,y_trainset)\n",
    "y_hat=clf.predict(X_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_testset, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_testset, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_testset, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_testset, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_testset, y_hat)\n",
    "CM = CM / CM.astype(np.float).sum(axis=1)\n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(CM, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already miles ahead of where we were with the decision tree classifier. \n",
    "\n",
    "Let's take a deeper look at the features to see if we can improve the model any further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=df_test_over[predictor_columns].columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these features are next to useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_filter = ['Crash_Time',\n",
    "'Day_of_Week',\n",
    "'Crash_Speed_Limit',\n",
    "'FHE_Collsn_ID',\n",
    "'Pop_Group_ID',\n",
    "'Surf_Type_ID',\n",
    "'Othr_Factr_ID',\n",
    "'Obj_Struck_ID',\n",
    "'Road_Cls_ID',\n",
    "'Wthr_Cond_ID',\n",
    "'Light_Cond_ID',\n",
    "'Crash_Sev_ID']\n",
    "\n",
    "new_predictors = ['Crash_Time',\n",
    "'Day_of_Week',\n",
    "'Crash_Speed_Limit',\n",
    "'FHE_Collsn_ID',\n",
    "'Pop_Group_ID',\n",
    "'Surf_Type_ID',\n",
    "'Othr_Factr_ID',\n",
    "'Obj_Struck_ID',\n",
    "'Road_Cls_ID',\n",
    "'Wthr_Cond_ID',\n",
    "'Light_Cond_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_over[new_predictors].values\n",
    "y = df_test_over[\"Crash_Sev_ID\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 60, 60, endpoint=True)\n",
    "train_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth)\n",
    "   dt.fit(x_train, y_train)\n",
    "   train_pred = dt.predict(x_test)\n",
    "   train_pred_score = metrics.accuracy_score(y_test, train_pred)\n",
    "   train_results.append(train_pred_score)\n",
    "\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1 = plt.plot(max_depths, train_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crashTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 34)\n",
    "crashTree.fit(x_train,y_train)\n",
    "y_hat = crashTree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_test, y_hat)\n",
    "CM = CM / CM.astype(np.float).sum(axis=1)\n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(CM, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(x_train,y_train)\n",
    "y_hat=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_test, y_hat)\n",
    "CM = CM / CM.astype(np.float).sum(axis=1)\n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(CM, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost accuracy on the decision tree by dropping those rows, 91.13% down to 91.07%.\n",
    "\n",
    "We also slightly lost accuracy on the random forest, but we got our best F1 score yet.\n",
    "\n",
    "I am comfortable with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing the model</h2>\n",
    "\n",
    "To see if the model can perform consistently, let's test the model against data that the model has never seen before. I've downloaded the crash data from 2016. Let's put it through the same normalization pipeline first, and run them through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('crash_2016.csv')\n",
    "test_df_filtered = test_df[new_filter]\n",
    "test_df_filtered = test_df_filtered[test_df_filtered.Crash_Sev_ID != 0]\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^N$', value=0, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^Y$', value=1, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^MON$', value=1, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^TUE$', value=2, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^WED$', value=3, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^THU$', value=4, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^FRI$', value=5, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^SAT$', value=6, regex=True)\n",
    "test_df_filtered = test_df_filtered.replace(to_replace=r'^SUN$', value=7, regex=True)\n",
    "test_df_filtered['Crash_Time'] = pd.to_datetime(test_df_filtered['Crash_Time']).astype('int64')\n",
    "max_a = test_df_filtered.Crash_Time.max()\n",
    "min_a = test_df_filtered.Crash_Time.min()\n",
    "min_norm = -1\n",
    "max_norm =1\n",
    "test_df_filtered['NORMTIME'] = (test_df_filtered.Crash_Time- min_a) *(max_norm - min_norm) / (max_a-min_a) + min_norm\n",
    "test_df_filtered.drop('Crash_Time', axis=1, inplace=True)\n",
    "test_df_filtered.rename(columns={'NORMTIME' : \"Crash_Time\"}, inplace=True)\n",
    "test_df_filtered = test_df_filtered[test_df_filtered['Crash_Speed_Limit']!=-1]\n",
    "test_df_filtered.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df_filtered[new_predictors].values\n",
    "y = test_df_filtered[\"Crash_Sev_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = crashTree.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y, y_hat)\n",
    "CM = CM / CM.astype(np.float).sum(axis=1)\n",
    "labels = ['1', '2', '3', '4', '5']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(CM, cmap=plt.cm.Reds)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y, y_hat, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, y_hat, average=None)"
   ]
  }
 ]
}